{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMgnoDR0Ract",
        "outputId": "55a2d4ca-67ab-4b9f-9c16-8089b7ec101a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "104"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "ord(\"h\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ord('ðŸ¤£')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8LufyckR44p",
        "outputId": "40d1f033-ee44-470a-8f88-82c06bcac0b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "129315"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[ord(x) for x in \"hello world\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC-XA5ypSAu-",
        "outputId": "7b2c6457-2777-4531-a92b-9c8c2650afe7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[104, 101, 108, 108, 111, 32, 119, 111, 114, 108, 100]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(\"hello world\".encode(\"utf-8\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzSvO9n6SJ3K",
        "outputId": "a6953a14-75ef-45e7-c32f-48068a5521fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[104, 101, 108, 108, 111, 32, 119, 111, 114, 108, 100]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(\"hello world\".encode(\"utf-16\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sa5jQ87WS3aX",
        "outputId": "e8e26909-6b79-4103-a6b8-3f3a5024906a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[255,\n",
              " 254,\n",
              " 104,\n",
              " 0,\n",
              " 101,\n",
              " 0,\n",
              " 108,\n",
              " 0,\n",
              " 108,\n",
              " 0,\n",
              " 111,\n",
              " 0,\n",
              " 32,\n",
              " 0,\n",
              " 119,\n",
              " 0,\n",
              " 111,\n",
              " 0,\n",
              " 114,\n",
              " 0,\n",
              " 108,\n",
              " 0,\n",
              " 100,\n",
              " 0]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(\"hello world\".encode(\"utf-32\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "LgvmcOP1S51n",
        "outputId": "82345a9f-879e-4f68-c44d-38c5185966a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[255,\n",
              " 254,\n",
              " 0,\n",
              " 0,\n",
              " 104,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 101,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 108,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 108,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 111,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 32,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 119,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 111,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 114,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 108,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 100,\n",
              " 0,\n",
              " 0,\n",
              " 0]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"The Tokenizer is a necessary and pervasive component of Large Language Models (LLMs), where it translates between strings and tokens (text chunks). Tokenizers are a completely separate stage of the LLM pipeline: they have their own training sets, training algorithms (Byte Pair Encoding), and after training implement two fundamental functions: encode() from strings to tokens, and decode() back from tokens to strings. In this lecture we build from scratch the Tokenizer used in the GPT series from OpenAI. In the process, we will see that a lot of weird behaviors and problems of LLMs actually trace back to tokenization. We'll go through a number of these issues, discuss why tokenization is at fault, and why someone out there ideally finds a way to delete this stage entirely.\"\n",
        "tokens = text.encode(\"utf-8\") # raw byte\n",
        "tokens = list(map(int, tokens)) # convert list of interger in range 0..255 for convenience\n",
        "print(text)\n",
        "print(\"Length : \", len(text))\n",
        "print(\"Tokens : \", len(tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyUMZ953S-ma",
        "outputId": "9d2ea355-333b-463d-f402-400b64fc21f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Tokenizer is a necessary and pervasive component of Large Language Models (LLMs), where it translates between strings and tokens (text chunks). Tokenizers are a completely separate stage of the LLM pipeline: they have their own training sets, training algorithms (Byte Pair Encoding), and after training implement two fundamental functions: encode() from strings to tokens, and decode() back from tokens to strings. In this lecture we build from scratch the Tokenizer used in the GPT series from OpenAI. In the process, we will see that a lot of weird behaviors and problems of LLMs actually trace back to tokenization. We'll go through a number of these issues, discuss why tokenization is at fault, and why someone out there ideally finds a way to delete this stage entirely.\n",
            "Length :  781\n",
            "Tokens :  781\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens[:200]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dNCgvOq-VRTs",
        "outputId": "e58afe29-99ca-4797-d105-ce95a5c7138f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[84,\n",
              " 104,\n",
              " 101,\n",
              " 32,\n",
              " 84,\n",
              " 111,\n",
              " 107,\n",
              " 101,\n",
              " 110,\n",
              " 105,\n",
              " 122,\n",
              " 101,\n",
              " 114,\n",
              " 32,\n",
              " 105,\n",
              " 115,\n",
              " 32,\n",
              " 97,\n",
              " 32,\n",
              " 110,\n",
              " 101,\n",
              " 99,\n",
              " 101,\n",
              " 115,\n",
              " 115,\n",
              " 97,\n",
              " 114,\n",
              " 121,\n",
              " 32,\n",
              " 97,\n",
              " 110,\n",
              " 100,\n",
              " 32,\n",
              " 112,\n",
              " 101,\n",
              " 114,\n",
              " 118,\n",
              " 97,\n",
              " 115,\n",
              " 105,\n",
              " 118,\n",
              " 101,\n",
              " 32,\n",
              " 99,\n",
              " 111,\n",
              " 109,\n",
              " 112,\n",
              " 111,\n",
              " 110,\n",
              " 101,\n",
              " 110,\n",
              " 116,\n",
              " 32,\n",
              " 111,\n",
              " 102,\n",
              " 32,\n",
              " 76,\n",
              " 97,\n",
              " 114,\n",
              " 103,\n",
              " 101,\n",
              " 32,\n",
              " 76,\n",
              " 97,\n",
              " 110,\n",
              " 103,\n",
              " 117,\n",
              " 97,\n",
              " 103,\n",
              " 101,\n",
              " 32,\n",
              " 77,\n",
              " 111,\n",
              " 100,\n",
              " 101,\n",
              " 108,\n",
              " 115,\n",
              " 32,\n",
              " 40,\n",
              " 76,\n",
              " 76,\n",
              " 77,\n",
              " 115,\n",
              " 41,\n",
              " 44,\n",
              " 32,\n",
              " 119,\n",
              " 104,\n",
              " 101,\n",
              " 114,\n",
              " 101,\n",
              " 32,\n",
              " 105,\n",
              " 116,\n",
              " 32,\n",
              " 116,\n",
              " 114,\n",
              " 97,\n",
              " 110,\n",
              " 115,\n",
              " 108,\n",
              " 97,\n",
              " 116,\n",
              " 101,\n",
              " 115,\n",
              " 32,\n",
              " 98,\n",
              " 101,\n",
              " 116,\n",
              " 119,\n",
              " 101,\n",
              " 101,\n",
              " 110,\n",
              " 32,\n",
              " 115,\n",
              " 116,\n",
              " 114,\n",
              " 105,\n",
              " 110,\n",
              " 103,\n",
              " 115,\n",
              " 32,\n",
              " 97,\n",
              " 110,\n",
              " 100,\n",
              " 32,\n",
              " 116,\n",
              " 111,\n",
              " 107,\n",
              " 101,\n",
              " 110,\n",
              " 115,\n",
              " 32,\n",
              " 40,\n",
              " 116,\n",
              " 101,\n",
              " 120,\n",
              " 116,\n",
              " 32,\n",
              " 99,\n",
              " 104,\n",
              " 117,\n",
              " 110,\n",
              " 107,\n",
              " 115,\n",
              " 41,\n",
              " 46,\n",
              " 32,\n",
              " 84,\n",
              " 111,\n",
              " 107,\n",
              " 101,\n",
              " 110,\n",
              " 105,\n",
              " 122,\n",
              " 101,\n",
              " 114,\n",
              " 115,\n",
              " 32,\n",
              " 97,\n",
              " 114,\n",
              " 101,\n",
              " 32,\n",
              " 97,\n",
              " 32,\n",
              " 99,\n",
              " 111,\n",
              " 109,\n",
              " 112,\n",
              " 108,\n",
              " 101,\n",
              " 116,\n",
              " 101,\n",
              " 108,\n",
              " 121,\n",
              " 32,\n",
              " 115,\n",
              " 101,\n",
              " 112,\n",
              " 97,\n",
              " 114,\n",
              " 97,\n",
              " 116,\n",
              " 101,\n",
              " 32,\n",
              " 115,\n",
              " 116,\n",
              " 97,\n",
              " 103,\n",
              " 101,\n",
              " 32,\n",
              " 111,\n",
              " 102,\n",
              " 32,\n",
              " 116,\n",
              " 104,\n",
              " 101,\n",
              " 32,\n",
              " 76,\n",
              " 76]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chr(32), chr(116)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-g6o_jBWZIM",
        "outputId": "6852caa0-1cf4-4f85-b363-bf26edb4eb9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(' ', 't')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_state(ids):\n",
        "    counts = {}\n",
        "    for pair in zip(ids, ids[1:]):\n",
        "        counts[pair] = counts.get(pair, 0) + 1\n",
        "    return counts\n",
        "\n",
        "state = get_state(tokens)\n",
        "print(state)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "iYJN7Lu0VU8V",
        "outputId": "a8e2ca5f-51c5-4e78-c23e-3aef9caa17c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{(84, 104): 1, (104, 101): 10, (101, 32): 24, (32, 84): 3, (84, 111): 3, (111, 107): 8, (107, 101): 8, (101, 110): 15, (110, 105): 8, (105, 122): 5, (122, 101): 3, (101, 114): 9, (114, 32): 6, (32, 105): 7, (105, 115): 6, (115, 32): 18, (32, 97): 16, (97, 32): 5, (32, 110): 2, (110, 101): 4, (101, 99): 3, (99, 101): 3, (101, 115): 6, (115, 115): 4, (115, 97): 1, (97, 114): 4, (114, 121): 1, (121, 32): 8, (97, 110): 8, (110, 100): 8, (100, 32): 9, (32, 112): 4, (112, 101): 3, (114, 118): 1, (118, 97): 1, (97, 115): 1, (115, 105): 1, (105, 118): 1, (118, 101): 2, (32, 99): 3, (99, 111): 5, (111, 109): 7, (109, 112): 3, (112, 111): 1, (111, 110): 5, (110, 116): 4, (116, 32): 8, (32, 111): 7, (111, 102): 5, (102, 32): 5, (32, 76): 4, (76, 97): 2, (114, 103): 1, (103, 101): 4, (110, 103): 8, (103, 117): 1, (117, 97): 2, (97, 103): 3, (32, 77): 1, (77, 111): 1, (111, 100): 4, (100, 101): 6, (101, 108): 5, (108, 115): 1, (32, 40): 3, (40, 76): 1, (76, 76): 3, (76, 77): 3, (77, 115): 2, (115, 41): 2, (41, 44): 2, (44, 32): 7, (32, 119): 8, (119, 104): 3, (114, 101): 5, (105, 116): 2, (32, 116): 27, (116, 114): 8, (114, 97): 7, (110, 115): 5, (115, 108): 1, (108, 97): 1, (97, 116): 7, (116, 101): 7, (32, 98): 5, (98, 101): 3, (101, 116): 4, (116, 119): 2, (119, 101): 4, (101, 101): 2, (110, 32): 6, (32, 115): 11, (115, 116): 5, (114, 105): 5, (105, 110): 13, (103, 115): 3, (116, 111): 9, (40, 116): 1, (101, 120): 1, (120, 116): 1, (99, 104): 2, (104, 117): 1, (117, 110): 3, (110, 107): 1, (107, 115): 1, (41, 46): 1, (46, 32): 4, (114, 115): 2, (112, 108): 2, (108, 101): 5, (108, 121): 4, (115, 101): 6, (101, 112): 1, (112, 97): 1, (116, 97): 3, (116, 104): 13, (77, 32): 1, (112, 105): 1, (105, 112): 1, (108, 105): 1, (101, 58): 1, (58, 32): 2, (101, 121): 1, (32, 104): 1, (104, 97): 3, (97, 118): 2, (101, 105): 2, (105, 114): 4, (111, 119): 1, (119, 110): 1, (97, 105): 4, (103, 32): 3, (116, 115): 1, (115, 44): 4, (97, 108): 4, (108, 103): 1, (103, 111): 2, (111, 114): 2, (104, 109): 1, (109, 115): 2, (40, 66): 1, (66, 121): 1, (121, 116): 1, (32, 80): 1, (80, 97): 1, (32, 69): 1, (69, 110): 1, (110, 99): 3, (100, 105): 2, (103, 41): 1, (97, 102): 1, (102, 116): 1, (105, 109): 1, (101, 109): 2, (109, 101): 3, (119, 111): 1, (111, 32): 6, (32, 102): 8, (102, 117): 2, (100, 97): 1, (97, 109): 1, (108, 32): 3, (99, 116): 3, (116, 105): 4, (105, 111): 4, (115, 58): 1, (32, 101): 2, (101, 40): 2, (40, 41): 2, (41, 32): 2, (102, 114): 4, (114, 111): 7, (109, 32): 4, (32, 100): 3, (98, 97): 2, (97, 99): 4, (99, 107): 2, (107, 32): 2, (115, 46): 1, (32, 73): 2, (73, 110): 2, (104, 105): 2, (32, 108): 2, (116, 117): 2, (117, 114): 1, (98, 117): 1, (117, 105): 1, (105, 108): 2, (108, 100): 1, (115, 99): 2, (99, 114): 1, (116, 99): 1, (104, 32): 2, (32, 117): 1, (117, 115): 2, (101, 100): 1, (32, 71): 1, (71, 80): 1, (80, 84): 1, (84, 32): 1, (105, 101): 1, (32, 79): 1, (79, 112): 1, (110, 65): 1, (65, 73): 1, (73, 46): 1, (112, 114): 2, (111, 99): 1, (119, 105): 1, (108, 108): 4, (108, 111): 1, (111, 116): 1, (114, 100): 1, (101, 104): 1, (118, 105): 1, (111, 98): 1, (98, 108): 1, (122, 97): 2, (110, 46): 1, (32, 87): 1, (87, 101): 1, (101, 39): 1, (39, 108): 1, (32, 103): 1, (104, 114): 1, (111, 117): 2, (117, 103): 1, (103, 104): 1, (110, 117): 1, (117, 109): 1, (109, 98): 1, (115, 117): 1, (117, 101): 1, (99, 117): 1, (104, 121): 2, (102, 97): 1, (97, 117): 1, (117, 108): 1, (108, 116): 1, (116, 44): 1, (115, 111): 1, (101, 111): 1, (117, 116): 1, (105, 100): 1, (101, 97): 1, (102, 105): 1, (100, 115): 1, (119, 97): 1, (97, 121): 1, (121, 46): 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_pair = max(state, key=state.get)\n",
        "top_pair"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RRghGV6WFAz",
        "outputId": "a84e2904-72e8-44c3-9268-bf2290d09835"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 116)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def merge(ids, pair, idx):\n",
        "    newids = []\n",
        "    i = 0\n",
        "    while i < len(ids):\n",
        "        if i < len(ids) - 1 and ids[i] == pair[0] and ids[i+1] == pair[1]:\n",
        "            newids.append(idx)\n",
        "            i += 2\n",
        "        else:\n",
        "            newids.append(ids[i])\n",
        "            i += 1\n",
        "    return newids\n",
        "\n",
        "print(merge([5, 6, 6, 7, 9, 1], (6, 7), 99))\n",
        "\n",
        "tokens2 = merge(tokens, top_pair, 256)\n",
        "print(tokens2)\n",
        "print(\"Length : \", len(tokens2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXOnjN9RWwDU",
        "outputId": "3a9ed70a-a816-4364-e9ac-fa2e6f81f86b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5, 6, 99, 9, 1]\n",
            "[84, 104, 101, 32, 84, 111, 107, 101, 110, 105, 122, 101, 114, 32, 105, 115, 32, 97, 32, 110, 101, 99, 101, 115, 115, 97, 114, 121, 32, 97, 110, 100, 32, 112, 101, 114, 118, 97, 115, 105, 118, 101, 32, 99, 111, 109, 112, 111, 110, 101, 110, 116, 32, 111, 102, 32, 76, 97, 114, 103, 101, 32, 76, 97, 110, 103, 117, 97, 103, 101, 32, 77, 111, 100, 101, 108, 115, 32, 40, 76, 76, 77, 115, 41, 44, 32, 119, 104, 101, 114, 101, 32, 105, 116, 256, 114, 97, 110, 115, 108, 97, 116, 101, 115, 32, 98, 101, 116, 119, 101, 101, 110, 32, 115, 116, 114, 105, 110, 103, 115, 32, 97, 110, 100, 256, 111, 107, 101, 110, 115, 32, 40, 116, 101, 120, 116, 32, 99, 104, 117, 110, 107, 115, 41, 46, 32, 84, 111, 107, 101, 110, 105, 122, 101, 114, 115, 32, 97, 114, 101, 32, 97, 32, 99, 111, 109, 112, 108, 101, 116, 101, 108, 121, 32, 115, 101, 112, 97, 114, 97, 116, 101, 32, 115, 116, 97, 103, 101, 32, 111, 102, 256, 104, 101, 32, 76, 76, 77, 32, 112, 105, 112, 101, 108, 105, 110, 101, 58, 256, 104, 101, 121, 32, 104, 97, 118, 101, 256, 104, 101, 105, 114, 32, 111, 119, 110, 256, 114, 97, 105, 110, 105, 110, 103, 32, 115, 101, 116, 115, 44, 256, 114, 97, 105, 110, 105, 110, 103, 32, 97, 108, 103, 111, 114, 105, 116, 104, 109, 115, 32, 40, 66, 121, 116, 101, 32, 80, 97, 105, 114, 32, 69, 110, 99, 111, 100, 105, 110, 103, 41, 44, 32, 97, 110, 100, 32, 97, 102, 116, 101, 114, 256, 114, 97, 105, 110, 105, 110, 103, 32, 105, 109, 112, 108, 101, 109, 101, 110, 116, 256, 119, 111, 32, 102, 117, 110, 100, 97, 109, 101, 110, 116, 97, 108, 32, 102, 117, 110, 99, 116, 105, 111, 110, 115, 58, 32, 101, 110, 99, 111, 100, 101, 40, 41, 32, 102, 114, 111, 109, 32, 115, 116, 114, 105, 110, 103, 115, 256, 111, 256, 111, 107, 101, 110, 115, 44, 32, 97, 110, 100, 32, 100, 101, 99, 111, 100, 101, 40, 41, 32, 98, 97, 99, 107, 32, 102, 114, 111, 109, 256, 111, 107, 101, 110, 115, 256, 111, 32, 115, 116, 114, 105, 110, 103, 115, 46, 32, 73, 110, 256, 104, 105, 115, 32, 108, 101, 99, 116, 117, 114, 101, 32, 119, 101, 32, 98, 117, 105, 108, 100, 32, 102, 114, 111, 109, 32, 115, 99, 114, 97, 116, 99, 104, 256, 104, 101, 32, 84, 111, 107, 101, 110, 105, 122, 101, 114, 32, 117, 115, 101, 100, 32, 105, 110, 256, 104, 101, 32, 71, 80, 84, 32, 115, 101, 114, 105, 101, 115, 32, 102, 114, 111, 109, 32, 79, 112, 101, 110, 65, 73, 46, 32, 73, 110, 256, 104, 101, 32, 112, 114, 111, 99, 101, 115, 115, 44, 32, 119, 101, 32, 119, 105, 108, 108, 32, 115, 101, 101, 256, 104, 97, 116, 32, 97, 32, 108, 111, 116, 32, 111, 102, 32, 119, 101, 105, 114, 100, 32, 98, 101, 104, 97, 118, 105, 111, 114, 115, 32, 97, 110, 100, 32, 112, 114, 111, 98, 108, 101, 109, 115, 32, 111, 102, 32, 76, 76, 77, 115, 32, 97, 99, 116, 117, 97, 108, 108, 121, 256, 114, 97, 99, 101, 32, 98, 97, 99, 107, 256, 111, 256, 111, 107, 101, 110, 105, 122, 97, 116, 105, 111, 110, 46, 32, 87, 101, 39, 108, 108, 32, 103, 111, 256, 104, 114, 111, 117, 103, 104, 32, 97, 32, 110, 117, 109, 98, 101, 114, 32, 111, 102, 256, 104, 101, 115, 101, 32, 105, 115, 115, 117, 101, 115, 44, 32, 100, 105, 115, 99, 117, 115, 115, 32, 119, 104, 121, 256, 111, 107, 101, 110, 105, 122, 97, 116, 105, 111, 110, 32, 105, 115, 32, 97, 116, 32, 102, 97, 117, 108, 116, 44, 32, 97, 110, 100, 32, 119, 104, 121, 32, 115, 111, 109, 101, 111, 110, 101, 32, 111, 117, 116, 256, 104, 101, 114, 101, 32, 105, 100, 101, 97, 108, 108, 121, 32, 102, 105, 110, 100, 115, 32, 97, 32, 119, 97, 121, 256, 111, 32, 100, 101, 108, 101, 116, 101, 256, 104, 105, 115, 32, 115, 116, 97, 103, 101, 32, 101, 110, 116, 105, 114, 101, 108, 121, 46]\n",
            "Length :  754\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 276\n",
        "num_merge = vocab_size - 256\n",
        "ids = list(tokens)\n",
        "\n",
        "merges = {}\n",
        "for i in range(num_merge):\n",
        "    stats = get_state(ids)\n",
        "    pair = max(stats, key=stats.get)\n",
        "    idx = 256 + i\n",
        "    print(f\"merging {pair} into new token {idx}\")\n",
        "    ids = merge(ids, pair, idx)\n",
        "    merges[pair] = idx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwHi1_aOX2to",
        "outputId": "5ffd4ef1-632e-4a6c-a147-8124b891eb83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "merging (32, 116) into new token 256\n",
            "merging (101, 32) into new token 257\n",
            "merging (115, 32) into new token 258\n",
            "merging (101, 110) into new token 259\n",
            "merging (105, 110) into new token 260\n",
            "merging (256, 104) into new token 261\n",
            "merging (101, 114) into new token 262\n",
            "merging (32, 115) into new token 263\n",
            "merging (256, 111) into new token 264\n",
            "merging (107, 259) into new token 265\n",
            "merging (32, 97) into new token 266\n",
            "merging (258, 97) into new token 267\n",
            "merging (110, 100) into new token 268\n",
            "merging (111, 109) into new token 269\n",
            "merging (114, 97) into new token 270\n",
            "merging (260, 103) into new token 271\n",
            "merging (32, 102) into new token 272\n",
            "merging (100, 101) into new token 273\n",
            "merging (265, 105) into new token 274\n",
            "merging (274, 122) into new token 275\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(tokens))\n",
        "print(len(ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iCo0ylFaWUZ",
        "outputId": "b65f42a6-ea41-4558-b911-671bd36550b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "781\n",
            "576\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decoding"
      ],
      "metadata": {
        "id": "bvYZ94XTcJ3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {idx : bytes([idx]) for idx in range(256)}\n",
        "for (p0, p1), idx in merges.items():\n",
        "    vocab[idx] = vocab[p0] + vocab[p1]\n",
        "\n",
        "def decode(ids):\n",
        "    tokens = b\"\".join(vocab[idx] for idx in ids)\n",
        "    text = tokens.decode(\"utf-8\", errors='replace')\n",
        "    return text\n",
        "\n",
        "print(decode([273]))"
      ],
      "metadata": {
        "id": "eLJOy5zXarVW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d1efb33-99be-45db-bacc-1a90896fd718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "de\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### encoding"
      ],
      "metadata": {
        "id": "9iX3FTRXDikZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(text):\n",
        "    tokens = list(text.encode(\"utf-8\"))\n",
        "    while len(tokens) >= 2:\n",
        "        stats = get_state(tokens)\n",
        "        pair = min(stats, key=lambda p : merges.get(p, float(\"inf\")))\n",
        "        if pair not in merges:\n",
        "            break\n",
        "        idx = merges[pair]\n",
        "        tokens = merge(tokens, pair, idx)\n",
        "    return tokens\n",
        "\n",
        "print(encode(\"Hello world\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1X1oZn9EDbK2",
        "outputId": "64a3b8a1-da83-4ded-f59e-8530921054f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[72, 101, 108, 108, 111, 32, 119, 111, 114, 108, 100]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode([72, 101, 108, 108, 111, 32, 119, 111, 114, 108, 100]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2QZpPl6FTqm",
        "outputId": "3a207902-7430-4e90-c31a-d21338f3102f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello world\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Forced splits using regex patterns (GPT series)"
      ],
      "metadata": {
        "id": "xc3cCOr2HaBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import regex as re\n",
        "\n",
        "gpt2pat = re.compile(r\"\"\"'s|'t|'re|'ve|'m|'ll|'d| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\")\n",
        "\n",
        "print(re.findall(gpt2pat, \"Hello123 world\"))\n",
        "print(re.findall(gpt2pat, \"Hello've world!!\"))\n",
        "print(re.findall(gpt2pat, \"How are you\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HauxBpfiF3sL",
        "outputId": "60d0b9da-5ec6-4111-b887-2ab3ce8dd350"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', '123', ' world']\n",
            "['Hello', \"'ve\", ' world', '!!']\n",
            "['How', ' are', ' you']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "enc = tiktoken.get_encoding(\"gpt2\")\n",
        "print(enc.encode(\"    Hello world!!!\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvdxZW-DHn0n",
        "outputId": "1cfdd700-2788-47d1-f445-982690324508"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[220, 220, 220, 18435, 995, 10185]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FqiDFu_NLhAt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}